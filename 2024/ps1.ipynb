{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dec9e0f-49cc-4efc-82a4-a3509b06c9a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Problem Set 1\n",
    "\n",
    "Solutions to Computational Problems\n",
    "\n",
    "## ATE under Exogeneity\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e539827b",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "290a5775",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Callable\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import expit\n",
    "from statsmodels.discrete.discrete_model import Probit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d67c5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _simulate_from_model(\n",
    "    treatment_effect: float | Callable,\n",
    "    n_samples: int,\n",
    "    n_sim: int,\n",
    "    seed: int,\n",
    "):\n",
    "    \"\"\"Simulate data from the model.\n",
    "\n",
    "    Args:\n",
    "        treatment_effect (float | Callable): Treatment effect. Must be a float or a\n",
    "            function that depends on the regressors.\n",
    "        n_samples (int): Number of samples per simulation.\n",
    "        n_sim (int): Number of simulations.\n",
    "        seed (int): Random seed that is passed to jax rng.\n",
    "\n",
    "    Returns:\n",
    "        - np.ndarray: Outcomes of shape (n_sim, n_samples).\n",
    "        - np.ndarray: Regressors of shape (n_sim, n_samples).\n",
    "        - np.ndarray: Binary treatment status of shape (n_sim, n_samples).\n",
    "\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    e = rng.normal(size=(n_sim, n_samples))\n",
    "    x = rng.uniform(size=(n_sim, n_samples))\n",
    "\n",
    "    propensity_score = expit(-(2 * x - 0.5))\n",
    "    d = rng.binomial(1, propensity_score)\n",
    "\n",
    "    te = treatment_effect(x) if callable(treatment_effect) else treatment_effect\n",
    "\n",
    "    y = te * d + 0.5 * x + e\n",
    "\n",
    "    return y, x, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1585715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _estimate_ate_via_naive_ols(y, x, d, with_intercept):\n",
    "    \"\"\"Estimate the ATE via the naive OLS estimator.\n",
    "\n",
    "    This regresses y on (1, d, x) if with_intercept is True, or on (d, x) if\n",
    "    with_intercept is False, and then takes the coefficient on d as the ATE.\n",
    "\n",
    "    \"\"\"\n",
    "    # build feature matrix for model y ~ 1 + d + x or y ~ d + x\n",
    "    if with_intercept:\n",
    "        features = np.column_stack((np.ones_like(d), d, x))\n",
    "    else:\n",
    "        features = np.column_stack((d, x))\n",
    "\n",
    "    coef = np.linalg.lstsq(features, y, rcond=None)[0]\n",
    "    return coef[1] if with_intercept else coef[0]\n",
    "\n",
    "\n",
    "def _estimate_ate_via_conditional_means(y, x, d):\n",
    "    \"\"\"Estimate the ATE via the conditional means estimator.\n",
    "\n",
    "    This estimates the conditional mean of y given x for each treatment group, and then\n",
    "    takes the difference between the two.\n",
    "\n",
    "    \"\"\"\n",
    "    # build feature matrix for model y ~ 1 + x\n",
    "    intercept = np.ones_like(x)\n",
    "    features = np.column_stack((intercept, x))\n",
    "\n",
    "    d_bool = d.astype(bool)\n",
    "\n",
    "    # get least squares cofficients for mu_1 and mu_0\n",
    "    coef_mu_1 = np.linalg.lstsq(features[d_bool], y[d_bool], rcond=None)[0]\n",
    "    coef_mu_0 = np.linalg.lstsq(features[~d_bool], y[~d_bool], rcond=None)[0]\n",
    "\n",
    "    # calculate mu_hat\n",
    "    mu_hat_1 = features @ coef_mu_1\n",
    "    mu_hat_0 = features @ coef_mu_0\n",
    "\n",
    "    # calculate the ate as the mean difference between the conditional expectations\n",
    "    return np.mean(mu_hat_1 - mu_hat_0, axis=0)\n",
    "\n",
    "\n",
    "def _estimate_ate_via_propensity_score(y, x, d):\n",
    "    \"\"\"Estimate the ATE via the propensity score estimator for a single simulation.\n",
    "\n",
    "    This fits a probit model to the treatment status d using x as a regressor, and then\n",
    "    estimates the ATE using the inverse probability weighting formula.\n",
    "\n",
    "    \"\"\"\n",
    "    # build feature matrix for simple probit model\n",
    "    intercept = np.ones_like(x)\n",
    "    features = np.column_stack((intercept, x))\n",
    "\n",
    "    # estimate probit model\n",
    "    model = Probit(\n",
    "        endog=d,\n",
    "        exog=features,\n",
    "    )\n",
    "    res = model.fit(maxiter=10, disp=False)\n",
    "\n",
    "    # get predictions\n",
    "    p_hat = res.predict(features)\n",
    "\n",
    "    return np.mean(d * y / p_hat - (1 - d) * y / (1 - p_hat))\n",
    "\n",
    "\n",
    "def estimate_ate(\n",
    "    y,\n",
    "    x,\n",
    "    d,\n",
    "    method,\n",
    "):\n",
    "    \"\"\"Estimate the average treatment effect (ATE) given the data.\n",
    "\n",
    "    Args:\n",
    "        y (np.ndarray): Outcomes of shape (n_sim, n_samples).\n",
    "        x (np.ndarray): Regressors of shape (n_sim, n_samples).\n",
    "        d (np.ndarray): Binary treatment status of shape (n_sim, n_samples).\n",
    "        method (str): Estimation method. Must be one of \"naive_ols\",\n",
    "            \"naive_ols_with_intercept\", \"conditional_means\", or \"propensity_score\".\n",
    "\n",
    "    Returns:\n",
    "        float or np.ndarray: Estimated ATE. If y is 1D, returns a float. If y is 2D,\n",
    "            returns a np.ndarray of shape (n_sim,).\n",
    "\n",
    "    \"\"\"\n",
    "    estimation_methods = {\n",
    "        \"naive_ols\": partial(_estimate_ate_via_naive_ols, with_intercept=False),\n",
    "        \"naive_ols_with_intercept\": partial(\n",
    "            _estimate_ate_via_naive_ols,\n",
    "            with_intercept=True,\n",
    "        ),\n",
    "        \"conditional_means\": _estimate_ate_via_conditional_means,\n",
    "        \"propensity_score\": _estimate_ate_via_propensity_score,\n",
    "    }\n",
    "    if method not in estimation_methods:\n",
    "        raise ValueError(f\"Invalid estimation method: {method}\")\n",
    "\n",
    "    estimation_func = estimation_methods[method]\n",
    "\n",
    "    if y.ndim == 1:\n",
    "        ate = estimation_func(y, x, d)\n",
    "    elif y.ndim == 2:\n",
    "        ate = np.array([estimation_func(y[i], x[i], d[i]) for i in range(y.shape[0])])\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid shape for y: {y.shape}\")\n",
    "\n",
    "    return ate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1295153e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation(n_samples, n_sim, seed=None):\n",
    "    \"\"\"Run a simulation.\n",
    "\n",
    "    Args:\n",
    "        n_samples (int): Number of samples per simulation.\n",
    "        n_sim (int): Number of simulations.\n",
    "        seed (int): Random seed.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe containing the results of the simulation.\n",
    "\n",
    "    \"\"\"\n",
    "    if seed is None:\n",
    "        seed = np.random.default_rng().integers(0, 2**32)\n",
    "\n",
    "    treatment_effects = {\n",
    "        \"constant\": 1.0,\n",
    "        \"function\": lambda x: 2 * (x < 0.5),\n",
    "    }\n",
    "\n",
    "    res = pd.DataFrame(columns=[\"treatment_effect\", \"method\"]).set_index(\n",
    "        [\"treatment_effect\", \"method\"],\n",
    "    )\n",
    "\n",
    "    for te_name, te in treatment_effects.items():\n",
    "\n",
    "        y, x, d = _simulate_from_model(\n",
    "            treatment_effect=te,\n",
    "            n_samples=n_samples,\n",
    "            n_sim=n_sim,\n",
    "            seed=seed,\n",
    "        )\n",
    "\n",
    "        for method in [\n",
    "            \"naive_ols\",\n",
    "            \"naive_ols_with_intercept\",\n",
    "            \"conditional_means\",\n",
    "            \"propensity_score\",\n",
    "        ]:\n",
    "\n",
    "            ate = estimate_ate(y, x, d, method=method)\n",
    "\n",
    "            res.loc[(te_name, method), \"sim_ate_mean\"] = ate.mean()\n",
    "            res.loc[(te_name, method), \"sim_ate_var\"] = ate.var()\n",
    "\n",
    "    return res.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0b2bb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = simulation(n_samples=500, n_sim=1_000, seed=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c95a6946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sim_ate_mean</th>\n",
       "      <th>sim_ate_var</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treatment_effect</th>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">constant</th>\n",
       "      <th>conditional_means</th>\n",
       "      <td>1.000326</td>\n",
       "      <td>0.008763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive_ols</th>\n",
       "      <td>1.001274</td>\n",
       "      <td>0.006289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive_ols_with_intercept</th>\n",
       "      <td>1.000079</td>\n",
       "      <td>0.008609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>propensity_score</th>\n",
       "      <td>1.001124</td>\n",
       "      <td>0.008978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">function</th>\n",
       "      <th>conditional_means</th>\n",
       "      <td>1.002250</td>\n",
       "      <td>0.011915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive_ols</th>\n",
       "      <td>1.422316</td>\n",
       "      <td>0.010003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive_ols_with_intercept</th>\n",
       "      <td>1.115790</td>\n",
       "      <td>0.012529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>propensity_score</th>\n",
       "      <td>0.998062</td>\n",
       "      <td>0.011688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sim_ate_mean  sim_ate_var\n",
       "treatment_effect method                                             \n",
       "constant         conditional_means             1.000326     0.008763\n",
       "                 naive_ols                     1.001274     0.006289\n",
       "                 naive_ols_with_intercept      1.000079     0.008609\n",
       "                 propensity_score              1.001124     0.008978\n",
       "function         conditional_means             1.002250     0.011915\n",
       "                 naive_ols                     1.422316     0.010003\n",
       "                 naive_ols_with_intercept      1.115790     0.012529\n",
       "                 propensity_score              0.998062     0.011688"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res  # noqa: B018"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98340e5b-f1ae-452d-a368-9706a954fb8b",
   "metadata": {},
   "source": [
    "## Instrumental Variables\n",
    "\n",
    "--- \n",
    "\n",
    "## Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "053cead9-2578-4d9b-a428-2033db9748a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_feather(\"data/angrist_and_evans.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd75abfc-0efe-4ea7-abe4-77369b10fb4e",
   "metadata": {},
   "source": [
    "> If you don't have the data stored as a feather file you can use\n",
    "> ```python\n",
    "> pd.read_excel(\"path/to/excel/file\")\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c0f244f-98c6-4d2a-979c-80247372e323",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dependent_variables_info = {\n",
    "    \"workedm\": \"Worked for pay\",\n",
    "    \"weeksm1\": \"Weeks worked\",\n",
    "    \"hourswm\": \"Hours worked\",\n",
    "    \"incomem\": \"Labor income\",\n",
    "    \"famincl\": \"Log family income\",\n",
    "}\n",
    "\n",
    "independent_variables = [\n",
    "    \"morekids\",\n",
    "    \"agem1\",\n",
    "    \"agefstm\",\n",
    "    \"boy1st\",\n",
    "    \"boy2nd\",\n",
    "    \"blackm\",\n",
    "    \"hispm\",\n",
    "    \"othracem\",\n",
    "]\n",
    "\n",
    "instrumental_mapping = {\"morekids\": \"samesex\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc8a0bc-929c-4833-9ed5-17114e1b8e62",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc8f3c52-52c4-42fd-a176-dc7f686957a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _cov_sandwich_estimator_ols(x: np.ndarray, e: np.ndarray) -> np.ndarray:\n",
    "    r\"\"\"Estimator for the asymptotic covariance matrix of OLS estimator.\n",
    "\n",
    "    The code corresponds to the HC0 estimator of $V_\\hat{\\beta}}$. For reference see\n",
    "    Section 7.8 in Econometrics by Bruce Hansen (version January 29, 2021).\n",
    "\n",
    "    Args:\n",
    "        x (np.ndarray): Regressors, shape (n, p).\n",
    "        e (np.ndarray): Residuals, shape (n,)\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Asymptotic covariance matrix, shape (p, p)\n",
    "\n",
    "    \"\"\"\n",
    "    xtx_inverse = np.linalg.pinv(x.T @ x)\n",
    "    scaling = (x.T * e**2) @ x\n",
    "    return xtx_inverse @ scaling @ xtx_inverse\n",
    "\n",
    "\n",
    "def _cov_sandwich_estimator_iv(\n",
    "    x: np.ndarray,\n",
    "    z: np.ndarray,\n",
    "    e: np.ndarray,\n",
    ") -> np.ndarray:\n",
    "    r\"\"\"Estimator for the asymptotic covariance matrix of 2SLS IV estimator.\n",
    "\n",
    "    The code corresponds to the heteroskedasticity-robust estimator of $V_\\\\hat{\\beta}}$\n",
    "    For reference see Section 12.18 in Econometrics by Bruce Hansen (version January 29,\n",
    "    2021).\n",
    "\n",
    "    Args:\n",
    "        x (np.ndarray): Regressors, shape (n, p).\n",
    "        z (np.ndarray): Instruments, shape (n, p).\n",
    "        e (np.ndarray): Residuals, shape (n,)\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Asymptotic covariance matrix, shape (p, p)\n",
    "\n",
    "    \"\"\"\n",
    "    ztz_inv = np.linalg.pinv(z.T @ z)\n",
    "    ztx = z.T @ x\n",
    "    xtz = ztx.T\n",
    "    outer = np.linalg.pinv(xtz @ ztz_inv @ ztx) @ xtz @ ztz_inv\n",
    "    scaling = (z.T * e**2) @ z\n",
    "    return outer @ scaling @ outer.T\n",
    "\n",
    "\n",
    "def _format_entries(coef: str, se: str) -> str:\n",
    "    \"\"\"Paste together two strings.\"\"\"\n",
    "    return f\"{coef:.4f} ({se:.4f})\"\n",
    "\n",
    "\n",
    "def _format_frame(result_frame: pd.DataFrame, name: str) -> pd.DataFrame:\n",
    "    \"\"\"Format coef and se column to single.\n",
    "\n",
    "    Args:\n",
    "        result_frame (pd.DataFrame): Result frame; has columns only \"coef\" and \"se\".\n",
    "        name (str): Name of the new column.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Formatted frame.\n",
    "\n",
    "    \"\"\"\n",
    "    str_repr = [_format_entries(*row[1]) for row in result_frame.iterrows()]\n",
    "    return pd.DataFrame(str_repr, index=result_frame.index, columns=[name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e403e1-8228-43ae-ad34-4bb0d3a30373",
   "metadata": {},
   "source": [
    "### OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42939fe2-53e1-4632-9d58-941bb351bf73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get y and x from data\n",
    "\n",
    "\n",
    "y = data[dependent_variables_info.keys()]\n",
    "\n",
    "features = data[independent_variables]\n",
    "\n",
    "# add intercept\n",
    "x = np.column_stack([np.ones(len(data)), features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38ff057f-5a15-4e12-bf41-2b1b08448dd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run least squares regression for each dependent variable\n",
    "\n",
    "coef_ols, *_ = np.linalg.lstsq(x, y, rcond=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bd16ac3-a614-4a00-b895-46c87a3e2719",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# store the result with correct index and column names\n",
    "\n",
    "coef_ols = pd.DataFrame(\n",
    "    coef_ols,\n",
    "    index=[\"intercept\", *independent_variables],\n",
    "    columns=y.columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5443db5f-20db-45e3-aa43-99c3fb0d3cb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compute standard errors for each dependent variable\n",
    "\n",
    "residuals = y - x @ coef_ols\n",
    "\n",
    "se_ols = {}\n",
    "\n",
    "for outcome in dependent_variables_info:\n",
    "    residual_array = residuals[outcome].to_numpy().flatten()\n",
    "\n",
    "    cov = _cov_sandwich_estimator_ols(x, e=residual_array)\n",
    "\n",
    "    se_ols[outcome] = pd.Series(np.sqrt(np.diag(cov)), index=coef_ols.index)\n",
    "\n",
    "\n",
    "se_ols = pd.DataFrame(se_ols, columns=y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6445fa26-dae3-46da-9828-aa3b3c32e874",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# combine coefficients and standard error in one frame\n",
    "\n",
    "result_ols = pd.concat(\n",
    "    [coef_ols.loc[\"morekids\"], se_ols.loc[\"morekids\"]],\n",
    "    axis=1,\n",
    "    keys=[\"coef\", \"se\"],\n",
    ")\n",
    "\n",
    "result_ols = result_ols.rename(mapper=dependent_variables_info, axis=0)\n",
    "\n",
    "result_ols = _format_frame(result_ols, name=\"ols\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8709ce3-bf3f-41f8-a306-334f1ef6ef66",
   "metadata": {},
   "source": [
    "## IV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2734c49c-5ba6-45e4-8d05-0401ead4c5e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get z from data (y and x are already defined)\n",
    "\n",
    "instruments_names = [\n",
    "    instrumental_mapping.get(var, var) for var in independent_variables\n",
    "]\n",
    "\n",
    "instruments = data[instruments_names]\n",
    "\n",
    "# add intercept\n",
    "z = np.column_stack([np.ones(len(data)), instruments])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84d441ea-249b-4818-8c6c-25d00ecd0090",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run two-stage least squares regression\n",
    "\n",
    "# first stage\n",
    "\n",
    "first_stage_coef, *_ = np.linalg.lstsq(z, x, rcond=None)\n",
    "x_predicted = z @ first_stage_coef\n",
    "\n",
    "# second stage\n",
    "\n",
    "coef_iv, *_ = np.linalg.lstsq(x_predicted, y, rcond=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4618b3fd-ddc3-430c-81ae-3f59cb72c143",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# store the result with the correct index and column names\n",
    "\n",
    "coef_iv = pd.DataFrame(\n",
    "    coef_iv,\n",
    "    index=[\"intercept\", *independent_variables],\n",
    "    columns=y.columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b825b476-aec3-435c-a049-b30cb5898ce3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compute standard errors for each dependent variable\n",
    "\n",
    "residuals = y - x @ coef_ols\n",
    "\n",
    "se_iv = {}\n",
    "\n",
    "for outcome in dependent_variables_info:\n",
    "    residual_array = residuals[outcome].to_numpy().flatten()\n",
    "\n",
    "    cov = _cov_sandwich_estimator_iv(x, z=z, e=residual_array)\n",
    "\n",
    "    se_iv[outcome] = pd.Series(np.sqrt(np.diag(cov)), index=coef_ols.index)\n",
    "\n",
    "\n",
    "se_iv = pd.DataFrame(se_iv, columns=y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3515250f-dd46-49ba-a1a1-60450b0aa1c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# combine coefficients and standard error in one frame\n",
    "\n",
    "result_iv = pd.concat(\n",
    "    [coef_iv.loc[\"morekids\"], se_iv.loc[\"morekids\"]],\n",
    "    axis=1,\n",
    "    keys=[\"coef\", \"se\"],\n",
    ")\n",
    "\n",
    "result_iv = result_iv.rename(mapper=dependent_variables_info, axis=0)\n",
    "\n",
    "result_iv = _format_frame(result_iv, name=\"iv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e73c87-3084-4b5b-9b02-57a88a156043",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a49d4b35-0dce-4cd9-9be1-87f3c0f105fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_result = pd.concat([result_ols, result_iv], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bcde880-c7c5-46b2-81b3-c356ac98c8ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ols</th>\n",
       "      <th>iv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Worked for pay</th>\n",
       "      <td>-0.1764 (0.0016)</td>\n",
       "      <td>-0.1173 (0.0251)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weeks worked</th>\n",
       "      <td>-8.9782 (0.0706)</td>\n",
       "      <td>-5.5588 (1.1147)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hours worked</th>\n",
       "      <td>-6.6467 (0.0610)</td>\n",
       "      <td>-4.5468 (0.9523)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Labor income</th>\n",
       "      <td>-3762.3826 (34.4127)</td>\n",
       "      <td>-1902.9526 (544.5210)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log family income</th>\n",
       "      <td>-0.1379 (0.0045)</td>\n",
       "      <td>-0.0253 (0.0683)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    ols                     iv\n",
       "Worked for pay         -0.1764 (0.0016)       -0.1173 (0.0251)\n",
       "Weeks worked           -8.9782 (0.0706)       -5.5588 (1.1147)\n",
       "Hours worked           -6.6467 (0.0610)       -4.5468 (0.9523)\n",
       "Labor income       -3762.3826 (34.4127)  -1902.9526 (544.5210)\n",
       "Log family income      -0.1379 (0.0045)       -0.0253 (0.0683)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_result  # noqa: B018"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
